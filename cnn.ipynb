{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4HI2mpwlrcn"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSPCom-KmApV"
   },
   "source": [
    "# Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import LeaveOneOut,KFold\n",
    "import tensorflow_hub as hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T05:11:32.261134Z",
     "iopub.status.busy": "2022-01-26T05:11:32.260310Z",
     "iopub.status.idle": "2022-01-26T05:11:34.742110Z",
     "shell.execute_reply": "2022-01-26T05:11:34.741254Z"
    },
    "id": "iAve6DCL4JH4"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import images\n",
    "#change user\n",
    "# path = \"C:\\\\Users\\\\amart50\\\\Documents\\\\Lifting data\\\\Data\"\n",
    "path ='C:\\\\Users\\\\amart50\\\\Desktop\\\\CNN_test\\\\data'\n",
    "deadlift = path + \"\\\\Deadlift\"\n",
    "bench = path + \"\\\\Bench\"\n",
    "squats = path + \"\\\\Squat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert deadlift to jpg\n",
    "# pos_paths_list = [deadlift, bench, squats]\n",
    "\n",
    "# for pos_paths in pos_paths_list:\n",
    "#     for file in os.listdir(pos_paths):\n",
    "#         # check the files which are end with specific extension\n",
    "#         if file.endswith(\".png\"):\n",
    "#             # print path name of selected files\n",
    "#             file_path = os.path.join(pos_paths, file)\n",
    "#             # print(file_path)\n",
    "#             im = Image.open(file_path)\n",
    "#             new_name = file.split(\".\")[0] + \".jpg\"\n",
    "#             # im.save(new_name)\n",
    "#             Image.open(file_path).convert('RGB').save(pos_paths+\"\\\\\"+new_name)\n",
    "\n",
    "\n",
    "#     for file in os.listdir(pos_paths):\n",
    "#         # check the files which are end with specific extension\n",
    "#         if file.endswith(\".jpeg\"):\n",
    "#             # print path name of selected files\n",
    "#             file_path = os.path.join(pos_paths, file)\n",
    "#             # print(file_path)\n",
    "#             im = Image.open(file_path)\n",
    "#             new_name = file.split(\".\")[0] + \".jpg\"\n",
    "#             # im.save(new_name)\n",
    "#             Image.open(file_path).convert('RGB').save(pos_paths+\"\\\\\"+new_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check\n",
    "# im = image.load_img(bench+\"\\\\1.jpg\")\n",
    "# plt.imshow(im)\n",
    "# # np.max( cv2.imread(bench+\"\\\\99.jpg\").flatten() )\n",
    "# cv2.imread(bench+\"\\\\99.jpg\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 841 images belonging to 3 classes.\n",
      "Found 209 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# normalise the pixel values\n",
    "train_ = ImageDataGenerator(validation_split = .2, rescale=1./255)\n",
    "TRAIN_DIR = path\n",
    "\n",
    "\n",
    "train_dataset = train_.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size = (224, 224),\n",
    "    subset='training',\n",
    "    batch_size = 10,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_dataset = train_.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size = (224, 224),\n",
    "    subset='validation',\n",
    "    class_mode='categorical',\n",
    "    batch_size = 10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset.shape\n",
    "mobilenet_v2 = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "feature_extractor_model = mobilenet_v2\n",
    "feature_extractor_layer = hub.KerasLayer(\n",
    "    feature_extractor_model,\n",
    "    input_shape=(224, 224, 3),\n",
    "    trainable=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "#   tf.keras.layers.Rescaling(1./255),\n",
    "feature_extractor_layer,\n",
    "# tf.keras.layers.Conv2D(16, (3,3), input_shape=(256,256,3), activation='relu'),\n",
    "# tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "# tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "# tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "# tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "# tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "# tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "# tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "# tf.keras.layers.Flatten(),\n",
    "# tf.keras.layers.Dense(128*4, activation='relu'),\n",
    "tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://stackoverflow.com/questions/57301698/how-to-change-a-learning-rate-for-adam-in-tf2\n",
    "# to reduce lr each run\n",
    "# model.fit(x_train, y_train, callbacks=[LearningRateReducerCb()], epochs=5)\n",
    "class LearningRateReducerCb(tf.keras.callbacks.Callback):\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    old_lr = self.model.optimizer.lr.read_value()\n",
    "    new_lr = old_lr * 0.99\n",
    "    print(\"\\nEpoch: {}. Reducing Learning Rate from {} to {}\".format(epoch, old_lr, new_lr))\n",
    "    self.model.optimizer.lr.assign(new_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "kfold = KFold(n_splits=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer_1 (KerasLayer)  (None, 1280)              2257984   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 3843      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,261,827\n",
      "Trainable params: 3,843\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model_fit = model.fit(train_dataset, epochs=5)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "85/85 [==============================] - 21s 206ms/step - loss: 0.8532 - accuracy: 0.6219 - val_loss: 0.5672 - val_accuracy: 0.7990\n",
      "Epoch 2/10\n",
      "85/85 [==============================] - 17s 199ms/step - loss: 0.4628 - accuracy: 0.8478 - val_loss: 0.4723 - val_accuracy: 0.8373\n",
      "Epoch 3/10\n",
      "85/85 [==============================] - 17s 193ms/step - loss: 0.3474 - accuracy: 0.8894 - val_loss: 0.4304 - val_accuracy: 0.8469\n",
      "Epoch 4/10\n",
      "85/85 [==============================] - 17s 197ms/step - loss: 0.2664 - accuracy: 0.9263 - val_loss: 0.3748 - val_accuracy: 0.8565\n",
      "Epoch 5/10\n",
      "85/85 [==============================] - 16s 193ms/step - loss: 0.2219 - accuracy: 0.9512 - val_loss: 0.3594 - val_accuracy: 0.8612\n",
      "Epoch 6/10\n",
      "85/85 [==============================] - 17s 195ms/step - loss: 0.1819 - accuracy: 0.9584 - val_loss: 0.3152 - val_accuracy: 0.8852\n",
      "Epoch 7/10\n",
      "85/85 [==============================] - 17s 196ms/step - loss: 0.1593 - accuracy: 0.9655 - val_loss: 0.3787 - val_accuracy: 0.8612\n",
      "Epoch 8/10\n",
      "85/85 [==============================] - 17s 194ms/step - loss: 0.1384 - accuracy: 0.9774 - val_loss: 0.3652 - val_accuracy: 0.8612\n",
      "Epoch 9/10\n",
      "85/85 [==============================] - 17s 195ms/step - loss: 0.1187 - accuracy: 0.9834 - val_loss: 0.3515 - val_accuracy: 0.8660\n",
      "Epoch 10/10\n",
      "85/85 [==============================] - 17s 194ms/step - loss: 0.1086 - accuracy: 0.9869 - val_loss: 0.3939 - val_accuracy: 0.8708\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "history = model.fit(\n",
    "  train_dataset,\n",
    "  validation_data=validation_dataset,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 3s 156ms/step - loss: 0.3939 - accuracy: 0.8708\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.39388173818588257, 0.8708133697509766]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.fit(x_train, y_train, callbacks=[LearningRateReducerCb()], epochs=5)\n",
    "model.evaluate(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "# plt.scale()\n",
    "plt.ylim([0,1.1])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(model,'my_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 577ms/step\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(\"C:\\\\Users\\\\amart50\\\\Downloads\\\\test.jpg\")\n",
    "image = tf.image.resize(image, (224, 224))  # Resize the image\n",
    "image = tf.keras.applications.mobilenet_v2.preprocess_input(image)  # Pre-process the image for the model\n",
    "image = image[None, ...]  # Add a batch dimension to the image\n",
    "\n",
    "# Use the model to classify the image\n",
    "predictions = model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.1010571e-01, 7.3406508e-04, 8.9160256e-02], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.54265463>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(predictions)[0, tf.argmax(predictions[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=1>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = tf.argmax([1,2], axis = 0)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Define a function to create the model\n",
    "# def create_model():\n",
    "#   # Build the model\n",
    "#   model = tf.keras.models.Sequential([\n",
    "#     tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "#     tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "#     tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "#     tf.keras.layers.Flatten(),\n",
    "#     tf.keras.layers.Dense(64, activation='relu'),\n",
    "#     tf.keras.layers.Dense(10, activation='softmax')\n",
    "#   ])\n",
    "\n",
    "#   # Compile the model\n",
    "#   model.compile(\n",
    "#     optimizer='adam',\n",
    "#     loss='sparse_categorical_crossentropy',\n",
    "#     metrics=['accuracy']\n",
    "#   )\n",
    "\n",
    "#   return model\n",
    "\n",
    "# # Load the data\n",
    "# (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# # Create a list of k models\n",
    "# k = 5\n",
    "# models = [create_model() for _ in range(k)]\n",
    "\n",
    "# # Define a function to evaluate the models\n",
    "# def evaluate_model(model, x, y):\n",
    "#   # Evaluate the model on the provided data\n",
    "#   return model.evaluate(x, y, verbose=0)\n",
    "\n",
    "# # Define a function to perform k-fold cross validation\n",
    "# def k_fold_cross_validation(k, x, y, evaluate_model):\n",
    "#   # Create a list to store the scores for each fold\n",
    "#   scores = []\n",
    "\n",
    "#   # Use the length of x as the number of samples\n",
    "#   num_samples = len(x)\n",
    "\n",
    "#   # Split the data into k folds\n",
    "#   folds = tf.split(x, num_or_size_splits=k)\n",
    "\n",
    "#   # Loop over the folds\n",
    "#   for i, fold in enumerate(folds):\n",
    "#     # Create the training and validation sets for this fold\n",
    "#     x_train = tf.concat(folds[:i] + folds[i+1:], axis=0)\n",
    "#     y_train = tf.concat(y[:i*num_samples//k] + y[(i+1)*num_samples//k:], axis=0)\n",
    "#     x_val = fold\n",
    "#     # y_val = y[i*num_samples//k:(i+1)*num_samples//k]\n",
    "\n",
    "#     # Train the model on the training data\n",
    "#     models[i].fit(x_train, y_train, epochs=10, verbose=0)\n",
    "\n",
    "#     # Evaluate the model on the validation data\n",
    "#     scores.append(evaluate_model(models[i], x_val, y_val))\n",
    "\n",
    "#   return scores\n",
    "\n",
    "# # Perform k-fold cross validation\n",
    "# scores = k_fold_cross_validation(k, x_train, y_train, evaluate_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cnn.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
